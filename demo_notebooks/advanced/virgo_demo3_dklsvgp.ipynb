{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-uhyy4p0GKt"
   },
   "source": [
    "## VIRGO: Scaling to full datasets with stochastic variational deep kernel learning Gaussian process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_C1sUJFTspiP"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install gpytorch\n",
    "!pip install pyfof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-0b-eSxGsoo4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gpytorch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "os.chdir(\"/content/drive/MyDrive/virgo/\")\n",
    "\n",
    "torch.manual_seed(2022)\n",
    "np.random.seed(2022)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# https://arxiv.org/pdf/1511.02222.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8f4ByeIxYWO3"
   },
   "outputs": [],
   "source": [
    "from virgo.data.cluster import VirgoCluster\n",
    "from virgo.data.cleaner import AutoDensityCleaner\n",
    "from virgo.models.kernel import VirgoKernel\n",
    "from virgo.models.mixture import VirgoMixture\n",
    "from virgo.models.dklmodel import DKLModel\n",
    "from virgo.models.dkltrainer import DKLTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFpqN7ncZaNK"
   },
   "outputs": [],
   "source": [
    "all_clusters = np.loadtxt('../data/virgo_data/vc_fitted_790_cluster.txt')[:, [0, 1, 2, 3, 4, 5, 6]]\n",
    "all_labs = np.loadtxt('../data/virgo_data/vc_fitted_790_cluster_labels.txt')\n",
    "# all_clusters = np.loadtxt('../data/virgo_data/vc_box_fitted_set0_cluster.txt')[:, [0, 1, 2, 3, 4, 5, 6]]\n",
    "# all_labs = np.loadtxt('../data/virgo_data/vc_box_fitted_set0_cluster_labels.txt')\n",
    "print(all_clusters.shape, all_labs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zyn-AwOlgorw"
   },
   "outputs": [],
   "source": [
    "# should be shuffled already\n",
    "all_data = np.array([*all_clusters.T, all_labs]).T\n",
    "np.random.shuffle(all_data)\n",
    "all_clusters = all_data[:, :-1]\n",
    "all_labs = all_data[:, -1].T\n",
    "all_labs_cp = all_labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5Ei2VUehBbi"
   },
   "outputs": [],
   "source": [
    "# Use only spatial points and shock normal (i.e. no Mach number and no HSML lenght)\n",
    "use_dim = [0, 1, 2, 3, 4, 5]\n",
    "n_dim = len(use_dim)\n",
    "n_classes = np.unique(all_labs_cp[all_labs_cp!=-1.]).shape[0]\n",
    "all_clusters = all_clusters[:, use_dim]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(all_clusters)\n",
    "all_clusters = scaler.transform(all_clusters)\n",
    "\n",
    "print(n_dim, n_classes)\n",
    "print(all_clusters.min(), all_clusters.max(), all_clusters.mean())\n",
    "print(all_clusters.shape, all_labs.shape)\n",
    "print(all_clusters[:5], all_labs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IFEkMwhmsoo6"
   },
   "outputs": [],
   "source": [
    "train_x_np = all_clusters[all_labs_cp!=-1.]\n",
    "train_y_np = all_labs_cp[all_labs_cp!=-1.]\n",
    "\n",
    "n_cut = int(train_x_np.shape[0] * 0.9)\n",
    "train_x = torch.tensor(train_x_np[:n_cut], dtype=torch.float32)\n",
    "train_y = torch.tensor(train_y_np[:n_cut], dtype=torch.float32)\n",
    "val_x = torch.tensor(train_x_np[n_cut:], dtype=torch.float32)\n",
    "val_y = torch.tensor(train_y_np[n_cut:], dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "val_dataset = TensorDataset(val_x, val_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=True)\n",
    "\n",
    "print(train_x.shape, train_y.shape, val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = DKLModel()\n",
    "likelihood = gpytorch.likelihoods.SoftmaxLikelihood(\n",
    "    num_features=model.num_feat,\n",
    "    num_classes=n_classes,\n",
    ")\n",
    "\n",
    "# summary(model, input_size=torch.rand(1024, n_dim).shape, device=\"cpu\")\n",
    "# for p in model.named_parameters():\n",
    "#     print(p)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    likelihood = likelihood.cuda()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "cDpkijgMNTQi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HiDLCpzIm5xk"
   },
   "outputs": [],
   "source": [
    "trainer = DKLTrainer(\n",
    "    model=model,\n",
    "    likelihood=likelihood,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cTXDTRIXw0Rd"
   },
   "outputs": [],
   "source": [
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plots\n",
    "fig, axs = plt.subplots(n_dim, 1, figsize=(4, 3 * n_dim))\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in trainer.val_loader:\n",
    "        if torch.cuda.is_available():\n",
    "                x_batch, y_batch = x_batch.cuda(), y_batch.cuda()\n",
    "        \n",
    "        x_batch = x_batch[::10]\n",
    "        y_batch = y_batch[::10]\n",
    "        # mean = torch.round(model(x_batch).mean).cpu()\n",
    "        # mean = (model(x_batch).mean).cpu()\n",
    "        output = likelihood(model(x_batch))  # This gives us 16 samples from the predictive distribution\n",
    "        mean = output.probs.mean(0).argmax(-1).cpu()\n",
    "        \n",
    "        for xdim in range(n_dim):\n",
    "            ax = axs[xdim]\n",
    "            \n",
    "            ax.plot(x_batch[:, xdim].cpu().detach().numpy(), mean.detach().numpy(), '*b')\n",
    "            ax.plot(x_batch[:, xdim].cpu().detach().numpy(), y_batch.cpu().detach().numpy(), 'xr', alpha=0.99)\n",
    "            ax.legend([ 'Mean', 'Observed Data'])\n",
    "            ax.set_title(f'Dim {xdim}')\n",
    "        break\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OFhwltg1nM3S"
   },
   "outputs": [],
   "source": [
    "# Plot full training data set\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "fig.suptitle(\"Full training data set\")\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "plot_data = all_clusters\n",
    "plot_y = all_labs\n",
    "print(plot_data.shape, plot_y.sum())\n",
    "ax.scatter(plot_data.T[0], plot_data.T[1], plot_data.T[2], c=plot_y, marker=\".\", cmap=\"plasma\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O__drqIeZBvx"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "fig.suptitle(\"Model predictions of full training data set\")\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "eval_data = torch.tensor(all_clusters, dtype=torch.float32)\n",
    "if torch.cuda.is_available(): \n",
    "    eval_data = eval_data.cuda()\n",
    "\n",
    "output = likelihood(model(eval_data))\n",
    "mean = output.probs.mean(0).argmax(-1).cpu()\n",
    "plot_y = mean.cpu().detach().numpy()\n",
    "plot_data = eval_data.cpu().detach().numpy()\n",
    "\n",
    "print(mean.min(), mean.max())\n",
    "print(plot_data.shape, mean.sum())\n",
    "ax.scatter(plot_data.T[0], plot_data.T[1], plot_data.T[2], c=plot_y, marker=\".\", cmap=\"plasma\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4rDFjJpkfOv"
   },
   "source": [
    "## Apply on raw data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WzevOw2KkoZV"
   },
   "outputs": [],
   "source": [
    "snap_id = 790\n",
    "filebase = f\"../data/virgo_data/250x_hd/snap_{snap_id}\"\n",
    "\n",
    "virgo_cluster = VirgoCluster(\n",
    "    file_name=filebase, io_mode=1, cut_mach_dim=-2, n_max_data=800000, \n",
    ")\n",
    "\n",
    "virgo_cluster.scale_data()\n",
    "virgo_cluster.print_datastats()\n",
    "virgo_cluster.plot_raw_hists(\n",
    "    bins=100, plot_range=[[2000., 8000.], [-6000., 1000.], [-3000., 6000.]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5FvUAEQk3G5"
   },
   "outputs": [],
   "source": [
    "virgo_kernel = VirgoKernel(virgo_cluster, k_nystroem=100, pca_comp=5)\n",
    "virgo_kernel()\n",
    "virgo_cluster.print_datastats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SqWWqBnik3LH"
   },
   "outputs": [],
   "source": [
    "virgo_mixture = VirgoMixture(virgo_cluster, n_comp=2)\n",
    "elbo = virgo_mixture.fit()\n",
    "\n",
    "print(f\"ELBO: {elbo}\")\n",
    "print(f\"Mixture weights {virgo_mixture.model.weights_}\")\n",
    "\n",
    "virgo_mixture.predict(remove_uncertain_labels=False)\n",
    "labels_removed = virgo_cluster.get_labels(return_counts=True)\n",
    "print(labels_removed)\n",
    "\n",
    "# virgo_cluster.cluster_labels[virgo_cluster.cluster_labels == 1] = 2\n",
    "# virgo_cluster.cluster_labels[virgo_cluster.cluster_labels == 1][0:100] = 4\n",
    "virgo_cluster.plot_cluster(cmap_vmax=4, n_step=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWYTL3Hyk3OU"
   },
   "outputs": [],
   "source": [
    "d_cleaner = AutoDensityCleaner(virgo_cluster)\n",
    "d_cleaner.clean()\n",
    "print(virgo_cluster.get_labels(return_counts=True))\n",
    "virgo_cluster.plot_cluster(n_step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPB1-dpHl-6n"
   },
   "outputs": [],
   "source": [
    "print(virgo_cluster.data.shape, virgo_cluster.cluster.shape, virgo_cluster.cluster_labels.shape)\n",
    "print(virgo_cluster.data[virgo_cluster.cluster_labels >= 0].shape)\n",
    "eval_data = virgo_cluster.cluster[virgo_cluster.cluster_labels >= 0]\n",
    "eval_data = scaler.transform(eval_data[:, [1, 2, 3, 4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H1jkVnu9m4qY"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(eval_data.T[0][::10], eval_data.T[1][::10], eval_data.T[2][::10], marker=\".\", cmap=\"plasma\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pGVOXXFfk3RD"
   },
   "outputs": [],
   "source": [
    "eval_data = torch.tensor(eval_data, dtype=torch.float32)\n",
    "if torch.cuda.is_available(): \n",
    "    eval_data = eval_data.cuda()\n",
    "\n",
    "output = likelihood(model(eval_data))\n",
    "mean = output.probs.mean(0).argmax(-1).cpu()\n",
    "for i in [0., 45., 90., 135., 180., 225., 270.]:\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    plot_y = mean.cpu().detach().numpy()\n",
    "    plot_data = eval_data.cpu().detach().numpy()\n",
    "\n",
    "    print(mean.min(), mean.max())\n",
    "    print(plot_data.shape, mean.sum())\n",
    "    ax.scatter(plot_data.T[0][::5], plot_data.T[1][::5], plot_data.T[2][::5], c=plot_y[::5], marker=\".\", cmap=\"plasma\")\n",
    "    ax.azim = i\n",
    "    ax.dist = 10\n",
    "    ax.elev = 30\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MT5OJW7csopE"
   },
   "outputs": [],
   "source": [
    "# SVGP https://docs.gpytorch.ai/en/stable/examples/04_Variational_and_Approximate_GPs/SVGP_Regression_CUDA.html\n",
    "# SVGP CLass https://docs.gpytorch.ai/en/stable/examples/04_Variational_and_Approximate_GPs/Non_Gaussian_Likelihoods.html\n",
    "# DKL Multiclass https://docs.gpytorch.ai/en/stable/examples/06_PyTorch_NN_Integration_DKL/Deep_Kernel_Learning_DenseNet_CIFAR_Tutorial.html\n",
    "# Exact Dirichlet https://docs.gpytorch.ai/en/stable/examples/01_Exact_GPs/GP_Regression_on_Classification_Labels.html?highlight=dirichlet\n",
    "\n",
    "# https://github.com/cornellius-gp/gpytorch/issues/1396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQEDjypms_6q"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "virgo_demo3_dklsvgp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}