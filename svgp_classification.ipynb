{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(694764, 7) (694764,) (694764,)\n"
     ]
    }
   ],
   "source": [
    "all_clusters = np.loadtxt('all_clusters.txt')\n",
    "all_labs = np.loadtxt('all_labs.txt')\n",
    "all_labs_cp = np.loadtxt('all_labs_cleaned.txt')\n",
    "print(all_clusters.shape, all_labs.shape, all_labs_cp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([692025, 7]) torch.Size([692025, 13])\n",
      "torch.float32 torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-7f96fddbc7b1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_y = torch.tensor(train_y, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "train_x = all_clusters[all_labs_cp!=-1.]\n",
    "train_y = all_labs_cp[all_labs_cp!=-1.]\n",
    "train_x = torch.tensor(train_x, dtype=torch.float32)\n",
    "train_y = torch.tensor(train_y, dtype=torch.int64)\n",
    "\n",
    "train_y = torch.nn.functional.one_hot(train_y)\n",
    "# convert y to one-hot vector for each event\n",
    "train_y = torch.tensor(train_y, dtype=torch.float32)\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(train_x.dtype, train_y.dtype)\n",
    "# print(train_x[:-10], train_y[:-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(torch.rand(10).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskBernoulliLikelihood(gpytorch.likelihoods.Likelihood):\n",
    "    def forward(self, function_samples, **kwargs):\n",
    "\n",
    "#         prob = torch.exp(function_samples)\n",
    "        prob = function_samples\n",
    "#         print(prob.shape, prob.dtype)\n",
    "        output_probs = torch.distributions.Normal(0, 1).cdf(prob)\n",
    "        out = torch.distributions.Independent(torch.distributions.Bernoulli(probs=output_probs), 1)\n",
    "#         out = torch.distributions.Independent(torch.distributions.Bernoulli(logits=output_probs), 1)\n",
    "#         print(out)\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 1000, 7])\n"
     ]
    }
   ],
   "source": [
    "num_latents = 9\n",
    "num_tasks = 13\n",
    "input_dim=train_x.shape[-1]\n",
    "num_ind_points = 1000\n",
    "\n",
    "class MultitaskGPModel(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self):\n",
    "        # Let's use a different set of inducing points for each latent function\n",
    "        inducing_points = torch.rand(num_latents, num_ind_points, input_dim)\n",
    "        print(inducing_points.shape)\n",
    "\n",
    "        # We have to mark the CholeskyVariationalDistribution as batch\n",
    "        # so that we learn a variational distribution for each task\n",
    "        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\n",
    "            inducing_points.size(-2), batch_shape=torch.Size([num_latents])\n",
    "        )\n",
    "\n",
    "        # We have to wrap the VariationalStrategy in a LMCVariationalStrategy\n",
    "        # so that the output will be a MultitaskMultivariateNormal rather than a batch output\n",
    "        variational_strategy = gpytorch.variational.LMCVariationalStrategy(\n",
    "            gpytorch.variational.VariationalStrategy(\n",
    "                self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "            ),\n",
    "            num_tasks=num_tasks,\n",
    "            num_latents=num_latents,\n",
    "            latent_dim=-1\n",
    "        )\n",
    "\n",
    "        super().__init__(variational_strategy)\n",
    "\n",
    "        # The mean and covariance modules should be marked as batch\n",
    "        # so we learn a different set of hyperparameters\n",
    "        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([num_latents]))\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.MaternKernel(batch_shape=torch.Size([num_latents])),\n",
    "            batch_shape=torch.Size([num_latents])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The forward function should be written as if we were dealing with each output\n",
    "        # dimension in batch\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "model = MultitaskGPModel()\n",
    "# likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=num_tasks)\n",
    "likelihood = MultitaskBernoulliLikelihood()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    likelihood = likelihood.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-65f0254e9b5e>:20: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  epochs_iter = tqdm.tqdm_notebook(range(num_epochs), desc=\"Epoch\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831abe7939444b418f5e5267771a0b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epoch'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87dcf1aef4f342b3b976d41763e2951c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Minibatch'), FloatProgress(value=0.0, max=676.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-65f0254e9b5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mminibatch_iter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},\n",
    "    {'params': likelihood.parameters()},\n",
    "], lr=0.1)\n",
    "\n",
    "# Our loss object. We're using the VariationalELBO, which essentially just computes the ELBO\n",
    "# print(train_y.size(0))\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_y.size(0))\n",
    "\n",
    "losses = []\n",
    "\n",
    "# We use more CG iterations here because the preconditioner introduced in the NeurIPS paper seems to be less\n",
    "# effective for VI.\n",
    "epochs_iter = tqdm.tqdm_notebook(range(num_epochs), desc=\"Epoch\")\n",
    "for i in epochs_iter:\n",
    "    # Within each iteration, we will go over each minibatch of data\n",
    "    minibatch_iter = tqdm.notebook.tqdm(train_loader, desc=\"Minibatch\", leave=False)\n",
    "    for x_batch, y_batch in minibatch_iter:\n",
    "        if torch.cuda.is_available():\n",
    "                x_batch, y_batch = x_batch.cuda(), y_batch.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "#         model.float()\n",
    "#         likelihood.double()\n",
    "    \n",
    "#         print(x_batch.dtype)\n",
    "#         print(y_batch.dtype)\n",
    "        \n",
    "        output = model(x_batch)\n",
    "        loss = -mll(output, y_batch)\n",
    "        losses.append(loss)\n",
    "        minibatch_iter.set_postfix(loss=loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        predictions = likelihood(output)\n",
    "    \n",
    "    \n",
    "plt.plot(losses)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plots\n",
    "fig, axs = plt.subplots(input_dim, (num_tasks-5), figsize=(3 * input_dim, 4 * (num_tasks -5)))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        if torch.cuda.is_available():\n",
    "                x_batch, y_batch = x_batch.cuda(), y_batch.cuda()\n",
    "                \n",
    "        predictions = likelihood(model(x_batch))\n",
    "#         mean = predictions.mean.ge(0.5).float()\n",
    "        mean = predictions.mean\n",
    "        \n",
    "        for xdim in range(7):\n",
    "            for task in range(num_tasks - 5):\n",
    "                ax = axs[xdim][task]\n",
    "                \n",
    "                \n",
    "                ax.plot(x_batch[:, xdim].detach().numpy(), mean[:, task].detach().numpy(), '*b')\n",
    "                ax.plot(x_batch[:, xdim].detach().numpy(), y_batch[:, task].detach().numpy(), 'xr', alpha=0.2)\n",
    "\n",
    "                # Shade in confidence\n",
    "        #         ax.fill_between(\n",
    "        #             test_x[:, xdim].detach().numpy(),\n",
    "        #             lower[:, task].detach().numpy(),\n",
    "        #             upper[:, task].detach().numpy(),\n",
    "        #             alpha=0.5,\n",
    "        #         )\n",
    "                ax.set_ylim([-0.1, 1.1])\n",
    "                ax.legend([ 'Mean', 'Observed Data','Confidence'])\n",
    "                ax.set_title(f'Task {task + 1}')\n",
    "        break\n",
    "\n",
    "fig.tight_layout()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "maes = []\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        if torch.cuda.is_available():\n",
    "                x_batch, y_batch = x_batch.cuda(), y_batch.cuda()\n",
    "        model.double()\n",
    "        x_batch = x_batch.double()\n",
    "        predictions = likelihood(model(x_batch))\n",
    "        preds = predictions.mean.ge(0.5).float()\n",
    "        \n",
    "#         print(y_batch[0])\n",
    "        if torch.rand(1) > 0.95:\n",
    "#             print(preds[0:5])\n",
    "            print(predictions.mean[0])\n",
    "        \n",
    "        mae = torch.mean(torch.abs(preds - y_batch))\n",
    "#         print(means.shape, preds.shape,y_batch.shape)\n",
    "        maes.append(mae.numpy())\n",
    "        break\n",
    "    \n",
    "maes = np.array(maes)\n",
    "print(maes.mean(), maes.min(), maes.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVGP https://docs.gpytorch.ai/en/stable/examples/04_Variational_and_Approximate_GPs/SVGP_Regression_CUDA.html\n",
    "# SVGP CLass https://docs.gpytorch.ai/en/stable/examples/04_Variational_and_Approximate_GPs/Non_Gaussian_Likelihoods.html\n",
    "# DKL Multiclass https://docs.gpytorch.ai/en/stable/examples/06_PyTorch_NN_Integration_DKL/Deep_Kernel_Learning_DenseNet_CIFAR_Tutorial.html\n",
    "# Exact Dirichlet https://docs.gpytorch.ai/en/stable/examples/01_Exact_GPs/GP_Regression_on_Classification_Labels.html?highlight=dirichlet\n",
    "\n",
    "# https://github.com/cornellius-gp/gpytorch/issues/1396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.07692308\n",
    "# tensor([0.1282, 0.1795, 0.0893, 0.0634, 0.0562, 0.0672, 0.0699, 0.0698, 0.0961,\n",
    "#         0.0345, 0.0263, 0.0643, 0.0166], dtype=torch.float64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
